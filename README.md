## 2021-10-08
|paper|code|
|---|---|
|[universal graph transformer self-attention networks](https://arxiv.org/abs/1909.11855)|[Graph-Transformer](https://github.com/daiquocnguyen/Graph-Transformer)|
|[artificial fingerprinting for generative models: rooting deepfake attribution in training data](https://arxiv.org/abs/2007.08457)|[ArtificialGANFingerprints](https://github.com/ningyu1991/ArtificialGANFingerprints)|
|[light field salient object detection: a review and benchmark](https://arxiv.org/abs/2010.04968)|[LFSOD-Survey](https://github.com/kerenfu/LFSOD-Survey)|
|[multi-agent reinforcement learning for visibility-based persistent monitoring](https://arxiv.org/abs/2011.01129)|[rl_multi_agent](https://github.com/raaslab/rl_multi_agent)|
|[full-glow: fully conditional glow for more realistic image generation](https://arxiv.org/abs/2012.05846)|[glow2](https://github.com/MoeinSorkhei/glow2)|
|[efficient two-stream network for violence detection using separable convolutional lstm](https://arxiv.org/abs/2102.10590)|[TwoStreamSepConvLSTM_ViolenceDetection](https://github.com/Zedd1558/TwoStreamSepConvLSTM_ViolenceDetection)|
|[what's in my lidar odometry toolbox?](https://arxiv.org/abs/2103.09708)|[pyLiDAR-SLAM](https://github.com/Kitware/pyLiDAR-SLAM)|
|[agentformer: agent-aware transformers for socio-temporal multi-agent forecasting](https://arxiv.org/abs/2103.14023)|[AgentFormer](https://github.com/Khrylx/AgentFormer)|
|[llc: accurate, multi-purpose learnt low-dimensional binary codes](https://arxiv.org/abs/2106.01487)|[LLC](https://github.com/RAIVNLab/LLC)|
|[align before fuse: vision and language representation learning with momentum distillation](https://arxiv.org/abs/2107.07651)|[ALBEF](https://github.com/salesforce/ALBEF)|
|[gait-learning with morphologically evolving robots generated by l-system](https://arxiv.org/abs/2107.08249)|[revolve](https://github.com/ci-group/revolve)|
|[aprel: a library for active preference-based reward learning algorithms](https://arxiv.org/abs/2108.07259)|[APReL](https://github.com/Stanford-ILIAD/APReL)|
|[a scaling law for synthetic-to-real transfer: how much is your pre-training effective?](https://arxiv.org/abs/2108.11018)|[cg-transfer](https://github.com/pfnet-research/cg-transfer)|
|[on assessing the usefulness of proxy domains for developing and evaluating embodied agents](https://arxiv.org/abs/2109.14516)|[gym-duckietown](https://github.com/duckietown/gym-duckietown)|
|[student helping teacher: teacher evolution via self-knowledge distillation](https://arxiv.org/abs/2110.00329)|[teskd](https://github.com/zhengli427/teskd)|
|[adaptive unfolding total variation network for low-light image enhancement](https://arxiv.org/abs/2110.00984)|[utvnet](https://github.com/charliezcj/utvnet)|
|[deepbbs: deep best buddies for point cloud registration](https://arxiv.org/abs/2110.03016)|[deepbbs](https://github.com/itanhe/deepbbs)|
|[large-scale topological radar localization using learned descriptors](https://arxiv.org/abs/2110.03081)|[radarloc](https://github.com/jac99/radarloc)|
|[speed+: next generation dataset for spacecraft pose estimation across domain gap](https://arxiv.org/abs/2110.03101)|[speedplusbaseline](https://github.com/tpark94/speedplusbaseline)|
|[efficient sharpness-aware minimization for improved training of neural networks](https://arxiv.org/abs/2110.03141)|[efficient_sam](https://github.com/dydjw9/efficient_sam)|
|[treegcn-ed: encoding point cloud using a tree-structured graph network](https://arxiv.org/abs/2110.03170)|[TreeGCN-ED](https://github.com/prajwalsingh/TreeGCN-ED)|
|[gradient step denoiser for convergent plug-and-play](https://arxiv.org/abs/2110.03220)|[gspnp](https://github.com/samuro95/gspnp)|
|[propagating state uncertainty through trajectory forecasting](https://arxiv.org/abs/2110.03267)|[psu-tf](https://github.com/stanfordasl/psu-tf)|
|[end-to-end supermask pruning: learning to prune image captioning models](https://arxiv.org/abs/2110.03298)|[sparse-image-captioning](https://github.com/jiahuei/sparse-image-captioning)|
|[optimized u-net for brain tumor segmentation](https://arxiv.org/abs/2110.03352)|[DeepLearningExamples](https://github.com/NVIDIA/DeepLearningExamples)|
|[inter-domain alignment for predicting high-resolution brain networks using teacher-student learning](https://arxiv.org/abs/2110.03452)|[L2S-KDnet](https://github.com/basiralab/L2S-KDnet)|
|[recurrent multigraph integrator network for predicting the evolution of population-driven brain connectivity templates](https://arxiv.org/abs/2110.03453)|[ReMI-Net](https://github.com/basiralab/ReMI-Net)|
|[unsupervised image decomposition with phase-correlation networks](https://arxiv.org/abs/2110.03473)|[Unsupervised-Decomposition-PCDNet](https://github.com/angelvillar96/Unsupervised-Decomposition-PCDNet)|
|[a few-shot learning graph multi-trajectory evolution network for forecasting multimodal baby connectivity development from a baseline timepoint](https://arxiv.org/abs/2110.03535)|[GmTE-Net](https://github.com/basiralab/GmTE-Net)|
|[towards accurate cross-domain in-bed human pose estimation](https://arxiv.org/abs/2110.03578)|[CD_HPE](https://github.com/MohamedAfham/CD_HPE)|
|[one thing to fool them all: generating interpretable, universal, and physically-realizable adversarial features](https://arxiv.org/abs/2110.03605)|[feature_fool](https://github.com/thestephencasper/feature_fool)|
|[dense gaussian processes for few-shot segmentation](https://arxiv.org/abs/2110.03674)|[dgpnet](https://github.com/joakimjohnander/dgpnet)|
## 2021-10-07
|paper|code|
|---|---|
|[medirl: predicting the visual attention of drivers via maximum entropy deep inverse reinforcement learning](https://arxiv.org/abs/1912.07773)|[MEDIRL-EyeCar](https://github.com/soniabaee/MEDIRL-EyeCar)|
|[similarity-based clustering for enhancing image classification architectures](https://arxiv.org/abs/2011.04728)|[Similarity-based-clustering-Official-research-module](https://github.com/Dishant-P/Similarity-based-clustering-Official-research-module)|
|[mpg: a multi-ingredient pizza image generator with conditional stylegans](https://arxiv.org/abs/2012.02821)|[MPG_Arxiv](https://github.com/klory/MPG_Arxiv)|
|[robust models are more interpretable because attributions look normal](https://arxiv.org/abs/2103.11257)|[boundary](https://github.com/zifanw/boundary)|
|[optimization for arbitrary-oriented object detection via representation invariance loss](https://arxiv.org/abs/2103.11636)|[RIDet](https://github.com/ming71/RIDet)|
|[learning a sketch tensor space for image inpainting of man-made scenes](https://arxiv.org/abs/2103.15087)|[MST_inpainting](https://github.com/ewrfcas/MST_inpainting)|
|[latentclr: a contrastive learning approach for unsupervised discovery of interpretable directions](https://arxiv.org/abs/2104.00820)|[latentclr](https://github.com/catlab-team/latentclr)|
|[the hidden label-marginal biases of segmentation losses](https://arxiv.org/abs/2104.08717)|[SegLossBias](https://github.com/by-liu/SegLossBias)|
|[robust 3d cell segmentation: extending the view of cellpose](https://arxiv.org/abs/2105.00794)|[Cellpose3D](https://github.com/stegmaierj/Cellpose3D)|
|[adversarial training with rectified rejection](https://arxiv.org/abs/2105.14785)|[Rectified-Rejection](https://github.com/P2333/Rectified-Rejection)|
|[wavelet-packet powered deepfake image detection](https://arxiv.org/abs/2106.09369)|[pytorch-wavelet-toolbox](https://github.com/v0lta/pytorch-wavelet-toolbox)|
|[adversarial visual robustness by causal intervention](https://arxiv.org/abs/2106.09534)|[ciiv-adversarial-robustness.pytorch](https://github.com/kaihuatang/ciiv-adversarial-robustness.pytorch)|
|[breast cancer diagnosis in two-view mammography using end-to-end trained efficientnet-based convolutional network](https://arxiv.org/abs/2110.01606)|[two-views-classifier](https://github.com/dpetrini/two-views-classifier)|
|[transformer assisted convolutional network for cell instance segmentation](https://arxiv.org/abs/2110.02270)|[segpc-2021](https://github.com/dsciitism/segpc-2021)|
|[seannet: semantic understanding network for localization under object dynamics](https://arxiv.org/abs/2110.02276)|[cognitive-map](https://github.com/xiaolisean/cognitive-map)|
|[enhancement of anime imaging enlargement using modified super-resolution cnn](https://arxiv.org/abs/2110.02321)|[SRCNN-anime](https://github.com/TanakitInt/SRCNN-anime)|
|[influence-balanced loss for imbalanced visual classification](https://arxiv.org/abs/2110.02444)|[ib-loss](https://github.com/pseulki/ib-loss)|
|[attack as the best defense: nullifying image-to-image translation gans via limit-aware adversarial attack](https://arxiv.org/abs/2110.02516)|[lasgsa](https://github.com/jimmy-academia/lasgsa)|
|[coarse-to-fine reasoning for visual question answering](https://arxiv.org/abs/2110.02526)|[crf_vqa](https://github.com/aioz-ai/crf_vqa)|
|[on the importance of firth bias reduction in few-shot classification](https://arxiv.org/abs/2110.02529)|[firth_bias_reduction](https://github.com/ehsansaleh/firth_bias_reduction)|
|[decoupled adaptation for cross-domain object detection](https://arxiv.org/abs/2110.02578)|[Transfer-Learning-Library](https://github.com/thuml/Transfer-Learning-Library)|
|[focus on the common good: group distributional robustness follows](https://arxiv.org/abs/2110.02619)|[cg-iclr22](https://github.com/vps-anonconfs/cg-iclr22)|
|[movingfashion: a benchmark for the video-to-shop challenge](https://arxiv.org/abs/2110.02627)|[seam-match-rcnn](https://github.com/humaticslab/seam-match-rcnn)|
|[s-extension patch: a simple and efficient way to extend an object detection model](https://arxiv.org/abs/2110.02670)|[S-Extension-patch-Official-research-module](https://github.com/Dishant-P/S-Extension-patch-Official-research-module)|
|[long-tailed distribution adaptation](https://arxiv.org/abs/2110.02686)|[lda](https://github.com/pengzhiliang/lda)|
|[mismatched no more: joint model-policy optimization for model-based rl](https://arxiv.org/abs/2110.02758)|[mnm](https://github.com/ben-eysenbach/mnm)|
|[adversarial robustness comparison of vision transformer and mlp-mixer to cnns](https://arxiv.org/abs/2110.02797)|[robustness_comparison_vit_mlp-mixer_cnn](https://github.com/phibenz/robustness_comparison_vit_mlp-mixer_cnn)|
|[accelerated first order methods for variational imaging](https://arxiv.org/abs/2110.02813)|[accelerated-first-order-method-for-variational-imaging](https://github.com/jbartlett6/accelerated-first-order-method-for-variational-imaging)|
|[efficient and high-quality prehensile rearrangement in cluttered and confined spaces](https://arxiv.org/abs/2110.02814)|[uniform_object_rearrangement](https://github.com/rui1223/uniform_object_rearrangement)|
|[semantic prediction: which one should come first, recognition or prediction?](https://arxiv.org/abs/2110.02829)|[pred_semantic](https://github.com/ais-bonn/pred_semantic)|
|[shallow features guide unsupervised domain adaptation for semantic segmentation at class boundaries](https://arxiv.org/abs/2110.02833)|[shallow_da](https://github.com/cvlab-unibo/shallow_da)|
|[climategan: raising climate change awareness by generating images of floods](https://arxiv.org/abs/2110.02871)|[climategan](https://github.com/cc-ai/climategan)|
|[meta internal learning](https://arxiv.org/abs/2110.02900)|[MetaInternalLearning](https://github.com/RaphaelBensTAU/MetaInternalLearning)|
